# transform_data/get_data.py

import pandas as pd
import pymongo
from bson.objectid import ObjectId
import os
import logging
import traceback
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# --- C·∫•u h√¨nh Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- ƒê·ªçc c·∫•u h√¨nh t·ª´ .env file ---
MONGO_URI = os.getenv('MONGO_URI', 'mongodb+srv://thaian:thaian123@taxanalyses.qxevmke.mongodb.net/?retryWrites=true&w=majority&appName=TaxAnalyses')
DATABASE_NAME = os.getenv('MONGO_DB_NAME', 'MolaDatabase')

if not MONGO_URI:
    raise ValueError("MONGO_URI not found in environment variables")

logging.info(f"‚úÖ Loaded MongoDB config from .env: {DATABASE_NAME}")
logging.info(f"üîó Atlas URI: {MONGO_URI[:50]}...")

# Validate configuration
if not MONGO_URI or not DATABASE_NAME:
    logging.error("Kh√¥ng th·ªÉ l·∫•y MONGO_URI ho·∫∑c DATABASE_NAME t·ª´ environment variables.")
    exit(1)



# --- C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n v√† file (v·ªõi header_keyword) ---

DATA_DIR = os.path.join(BASE_DIR, "data")



# ***** C·∫≠p nh·∫≠t c·∫•u h√¨nh v·ªõi header_keyword *****

FILES_CONFIG = {

    "KhachHang": {

        "base_name": "Danhmuckhachhang",

        "collection": "KhachHang",

        "sheet_name": "Sheet1",

        "header_keyword": "L√† t·ªï ch·ª©c/c√° nh√¢n", # T√¨m d√≤ng c√≥ t·ª´ n√†y ·ªü c·ªôt ƒë·∫ßu ti√™n

        "column_mapping": {

            "M√£ kh√°ch h√†ng (*)": "ma_khach_hang", # T√™n c·ªôt n√†y PH·∫¢I kh·ªõp v·ªõi header t√¨m ƒë∆∞·ª£c trong file

            "T√™n kh√°ch h√†ng (*)": "ten_khach_hang",

            "ƒê·ªãa ch·ªâ": "dia_chi",

            "M√£ s·ªë thu·∫ø": "ma_so_thue"

        },

        "required_columns": ["M√£ kh√°ch h√†ng (*)", "T√™n kh√°ch h√†ng (*)"] # T√™n c·ªôt n√†y PH·∫¢I kh·ªõp

    },

    "NhaCungCap": {

        "base_name": "Danhmucnhacungcap",

        "collection": "NhaCungCap",

        "sheet_name": "Sheet1",

        "header_keyword": "L√† t·ªï ch·ª©c/c√° nh√¢n", # T√¨m d√≤ng c√≥ t·ª´ n√†y ·ªü c·ªôt ƒë·∫ßu ti√™n

        "column_mapping": {

            "M√£ nh√† cung c·∫•p (*)": "ma_ncc_goc",

            "T√™n nh√† cung c·∫•p (*)": "ten_ncc",

            "ƒê·ªãa ch·ªâ": "dia_chi",

            "M√£ s·ªë thu·∫ø": "ma_so_thue"

        },

         "required_columns": ["M√£ nh√† cung c·∫•p (*)", "T√™n nh√† cung c·∫•p (*)"]

    },

    "DanhMucVatTu": {

        "base_name": "Danhmucvattu",

        "collection": "DanhMucVatTu",

        "sheet_name": "Sheet1",

        "header_keyword": "M√£", # T√¨m d√≤ng c√≥ t·ª´ n√†y ·ªü c·ªôt ƒë·∫ßu ti√™n (L∆∞u √Ω: c√≥ th·ªÉ c·∫ßn ch√≠nh x√°c h∆°n "M√£ (*)" t√πy file)

        "column_mapping": {

            "M√£ (*)": "ma_vt",

            "T√™n (*)": "ten_vat_tu",

            "T√≠nh ch·∫•t": "tinh_chat",

            "ƒê∆°n v·ªã t√≠nh ch√≠nh": "don_vi_tinh",

            "Nh√≥m VTHH": "nhom_VTHH",

            "Kho ng·∫ßm ƒë·ªãnh": "kho_ngam_dinh",

            "TK kho": "TK_kho"

        },

         "required_columns": ["M√£ (*)", "T√™n (*)"]

    }

}





def find_header_row(df, keyword):

    """T√¨m index c·ªßa d√≤ng ƒë·∫ßu ti√™n ch·ª©a keyword trong c·ªôt ƒë·∫ßu ti√™n."""

    if 0 not in df.columns: # Ki·ªÉm tra xem c·ªôt ƒë·∫ßu ti√™n (index 0) c√≥ t·ªìn t·∫°i kh√¥ng

        return -1



    # Chuy·ªÉn c·ªôt ƒë·∫ßu ti√™n th√†nh string, x·ª≠ l√Ω l·ªói n·∫øu c√≥ ki·ªÉu d·ªØ li·ªáu kh√¥ng ph√π h·ª£p

    try:

        first_col_str = df[0].astype(str).str.strip()

    except Exception as e:

        logging.error(f"Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi c·ªôt ƒë·∫ßu ti√™n th√†nh chu·ªói ƒë·ªÉ t√¨m header: {e}")

        return -1



    # T√¨m c√°c d√≤ng ch·ª©a keyword

    matching_rows = first_col_str[first_col_str.str.contains(keyword, na=False, case=False)] # case=False ƒë·ªÉ kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng



    if not matching_rows.empty:

        # L·∫•y index c·ªßa d√≤ng ƒë·∫ßu ti√™n kh·ªõp

        header_index = matching_rows.index[0]

        return header_index

    return -1 # Kh√¥ng t√¨m th·∫•y



def get_data(username):

    """

    ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV/XLSX, t·ª± ƒë·ªông t√¨m header, ghi v√†o MongoDB.

    S·ª≠ d·ª•ng username tr·ª±c ti·∫øp l√†m gi√° tr·ªã cho tr∆∞·ªùng 'username'.



    Args:

        username (str): Chu·ªói string b·∫•t k·ª≥ ƒë·∫°i di·ªán cho client/user.

    """

    # Ch·ªâ c·∫ßn log th√¥ng tin b·∫Øt ƒë·∫ßu, kh√¥ng c·∫ßn ki·ªÉm tra hay chuy·ªÉn ƒë·ªïi username

    logging.info(f"B·∫Øt ƒë·∫ßu qu√° tr√¨nh nh·∫≠p d·ªØ li·ªáu cho client (username): {username}")



    # Ki·ªÉm tra n·∫øu username r·ªóng (t√πy ch·ªçn, c√≥ th·ªÉ b·ªè n·∫øu mu·ªën ch·∫•p nh·∫≠n c·∫£ username r·ªóng)

    if not username:

         logging.warning("Username ƒë∆∞·ª£c cung c·∫•p l√† r·ªóng. C√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn vi·ªác truy v·∫•n sau n√†y.")

         # B·∫°n c√≥ th·ªÉ quy·∫øt ƒë·ªãnh return ·ªü ƒë√¢y n·∫øu kh√¥ng mu·ªën x·ª≠ l√Ω username r·ªóng

         # return



    mongo_client = None

    try:

        logging.info(f"ƒêang k·∫øt n·ªëi t·ªõi MongoDB...")

        mongo_client = pymongo.MongoClient(MONGO_URI)

        mongo_client.admin.command('ping') # Ki·ªÉm tra k·∫øt n·ªëi

        db = mongo_client[DATABASE_NAME]

        logging.info(f"K·∫øt n·ªëi th√†nh c√¥ng t·ªõi database: {DATABASE_NAME}")



        for config_key, config in FILES_CONFIG.items():

            base_name = config["base_name"]

            collection_name = config["collection"]

            sheet_name = config.get("sheet_name", 0)

            header_keyword = config["header_keyword"]

            column_mapping = config["column_mapping"]

            required_columns = config["required_columns"]

            collection = db[collection_name]



            base_path = os.path.join(DATA_DIR, base_name)

            csv_path = base_path + ".csv"

            xlsx_path = base_path + ".xlsx"



            actual_file_path = None

            is_csv = None



            if os.path.exists(csv_path):

                actual_file_path = csv_path

                is_csv = True

            elif os.path.exists(xlsx_path):

                actual_file_path = xlsx_path

                is_csv = False

            else:

                logging.warning(f"Kh√¥ng t√¨m th·∫•y file '{base_name}.csv' ho·∫∑c '{base_name}.xlsx' cho '{config_key}'. B·ªè qua.")

                continue



            file_type_str = "CSV" if is_csv else "XLSX"

            logging.info(f"--- B·∫Øt ƒë·∫ßu x·ª≠ l√Ω file {file_type_str}: {os.path.basename(actual_file_path)} ---")



            try:

                df_raw = None

                # ƒê·ªçc file v·ªõi header=None

                if is_csv:

                    try:

                        df_raw = pd.read_csv(actual_file_path, delimiter=';', header=None, encoding='utf-8', low_memory=False, skipinitialspace=True, dtype=str) # Th√™m dtype=str

                    except UnicodeDecodeError:

                        logging.warning(f"L·ªói ƒë·ªçc file {os.path.basename(actual_file_path)} b·∫±ng utf-8, th·ª≠ l·∫°i v·ªõi utf-8-sig.")

                        df_raw = pd.read_csv(actual_file_path, delimiter=';', header=None, encoding='utf-8-sig', low_memory=False, skipinitialspace=True, dtype=str) # Th√™m dtype=str

                else: # XLSX

                    try:

                        # ƒê·ªçc t·∫•t c·∫£ d·ªØ li·ªáu d∆∞·ªõi d·∫°ng string ƒë·ªÉ tr√°nh l·ªói ki·ªÉu d·ªØ li·ªáu v√† gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng

                        df_raw = pd.read_excel(actual_file_path, sheet_name=sheet_name, header=None, engine='openpyxl', dtype=str)

                    except ImportError:

                        logging.error("L·ªói: C·∫ßn c√†i ƒë·∫∑t 'openpyxl' ƒë·ªÉ ƒë·ªçc .xlsx. Ch·∫°y: pip install openpyxl")

                        continue

                    # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p sheet tr·ªëng tr·∫£ v·ªÅ None thay v√¨ DataFrame r·ªóng

                    if df_raw is None:

                        df_raw = pd.DataFrame()





                if df_raw.empty:

                    logging.warning(f"File {os.path.basename(actual_file_path)} tr·ªëng ho·∫∑c kh√¥ng ƒë·ªçc ƒë∆∞·ª£c d·ªØ li·ªáu.")

                    continue



                # T√¨m header v√† x·ª≠ l√Ω DataFrame

                header_row_index = find_header_row(df_raw, header_keyword)



                if header_row_index == -1:

                    logging.error(f"Kh√¥ng t√¨m th·∫•y d√≤ng header v·ªõi t·ª´ kh√≥a '{header_keyword}' trong file {os.path.basename(actual_file_path)}. B·ªè qua file n√†y.")

                    continue



                logging.info(f"T√¨m th·∫•y header t·∫°i d√≤ng index: {header_row_index}")



                # L·∫•y d√≤ng header l√†m t√™n c·ªôt m·ªõi (chuy·ªÉn th√†nh str v√† strip whitespace)

                new_columns = df_raw.iloc[header_row_index].astype(str).str.strip().replace(r'^\.+|\.+$', '', regex=True) # Th√™m replace ƒë·ªÉ x√≥a d·∫•u ch·∫•m th·ª´a

                # Ki·ªÉm tra t√™n c·ªôt tr√πng l·∫∑p v√† x·ª≠ l√Ω n·∫øu c·∫ßn (v√≠ d·ª• th√™m h·∫≠u t·ªë)

                if new_columns.duplicated().any():

                    logging.warning(f"Ph√°t hi·ªán t√™n c·ªôt tr√πng l·∫∑p trong header file {os.path.basename(actual_file_path)}: {new_columns[new_columns.duplicated()].tolist()}. C√¢n nh·∫Øc ch·ªânh s·ª≠a file g·ªëc ho·∫∑c x·ª≠ l√Ω ƒë·ªïi t√™n.")

                    # C√≥ th·ªÉ th√™m logic ƒë·ªïi t√™n t·ª± ƒë·ªông ·ªü ƒë√¢y n·∫øu mu·ªën



                df = df_raw.iloc[header_row_index + 1:].copy()

                df.columns = new_columns

                df.reset_index(drop=True, inplace=True)



                logging.info(f"Header sau khi x·ª≠ l√Ω: {list(df.columns)}")



                documents_to_insert = []

                skipped_rows = 0

                missing_cols_reported = set() # D√πng ƒë·ªÉ b√°o l·ªói 1 l·∫ßn cho m·ªói c·ªôt thi·∫øu



                # Ki·ªÉm tra xem c√°c c·ªôt y√™u c·∫ßu c√≥ t·ªìn t·∫°i trong header m·ªõi kh√¥ng

                current_file_missing_required = set()

                for req_col in required_columns:

                    # Ki·ªÉm tra b·∫±ng c√°ch chu·∫©n h√≥a (v√≠ d·ª•: lower case, strip) n·∫øu c·∫ßn

                    # req_col_normalized = str(req_col).strip().lower()

                    # found = any(str(col).strip().lower() == req_col_normalized for col in df.columns)

                    if req_col not in df.columns: # Ki·ªÉm tra tr·ª±c ti·∫øp tr∆∞·ªõc

                         current_file_missing_required.add(req_col)



                if current_file_missing_required:

                    logging.error(f"Thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc {list(current_file_missing_required)} trong header t√¨m ƒë∆∞·ª£c c·ªßa file {os.path.basename(actual_file_path)}. Header: {list(df.columns)}. B·ªè qua x·ª≠ l√Ω file n√†y.")

                    continue # B·ªè qua to√†n b·ªô file n·∫øu thi·∫øu c·ªôt b·∫Øt bu·ªôc



                # L·∫∑p qua c√°c d√≤ng d·ªØ li·ªáu ƒë√£ c√≥ header ƒë√∫ng

                for index, row in df.iterrows():

                    is_valid_row = True

                    # Ki·ªÉm tra gi√° tr·ªã c√°c c·ªôt b·∫Øt bu·ªôc kh√¥ng ƒë∆∞·ª£c r·ªóng

                    for req_col in required_columns:

                         # D√πng row.get(req_col, None) ƒë·ªÉ tr√°nh l·ªói n·∫øu c·ªôt b·∫•t ng·ªù b·ªã thi·∫øu d√π ƒë√£ check ·ªü tr√™n

                        cell_value = row.get(req_col, None)

                        # Coi None, NaN, chu·ªói r·ªóng, chu·ªói ch·ªâ ch·ª©a kho·∫£ng tr·∫Øng l√† kh√¥ng h·ª£p l·ªá

                        if pd.isna(cell_value) or str(cell_value).strip() == "":

                            is_valid_row = False

                            break # Ch·ªâ c·∫ßn 1 c·ªôt b·∫Øt bu·ªôc thi·∫øu l√† b·ªè qua d√≤ng



                    if not is_valid_row:

                        skipped_rows += 1

                        continue # B·ªè qua d√≤ng n√†y



                    # T·∫°o document ƒë·ªÉ insert

                    # ***** THAY ƒê·ªîI QUAN TR·ªåNG ·ªû ƒê√ÇY *****

                    doc = {"username": username} # S·ª≠ d·ª•ng username g·ªëc tr·ª±c ti·∫øp



                    # Map c√°c c·ªôt t·ª´ config sang document

                    for map_col, mongo_field in column_mapping.items():

                        if map_col in df.columns:

                            value = row[map_col]

                            # X·ª≠ l√Ω gi√° tr·ªã NaN ho·∫∑c None th√†nh chu·ªói r·ªóng, c√≤n l·∫°i th√†nh string v√† strip

                            if pd.isna(value):

                                doc[mongo_field] = ""

                            else:

                                doc[mongo_field] = str(value).strip()

                        else:

                            # Ch·ªâ log c·∫£nh b√°o n·∫øu c·ªôt mapping kh√¥ng c√≥ trong header t√¨m ƒë∆∞·ª£c

                            if map_col not in missing_cols_reported:

                                logging.warning(f"C·ªôt ƒë∆∞·ª£c map '{map_col}' (t·ª´ config) kh√¥ng c√≥ trong header t√¨m ƒë∆∞·ª£c c·ªßa file {os.path.basename(actual_file_path)}. Header: {list(df.columns)}. S·∫Ω d√πng gi√° tr·ªã m·∫∑c ƒë·ªãnh (chu·ªói r·ªóng).")

                                missing_cols_reported.add(map_col)

                            doc[mongo_field] = "" # G√°n gi√° tr·ªã m·∫∑c ƒë·ªãnh



                    documents_to_insert.append(doc)



                # Log v√† Ghi v√†o DB

                if skipped_rows > 0:

                    logging.warning(f"ƒê√£ b·ªè qua {skipped_rows} d√≤ng trong file {os.path.basename(actual_file_path)} do thi·∫øu d·ªØ li·ªáu ·ªü c√°c c·ªôt b·∫Øt bu·ªôc.")



                if documents_to_insert:

                    logging.info(f"Chu·∫©n b·ªã ghi {len(documents_to_insert)} documents t·ª´ file {os.path.basename(actual_file_path)} v√†o collection '{collection_name}'...")

                    try:

                        result = collection.insert_many(documents_to_insert, ordered=False)

                        logging.info(f"Ghi th√†nh c√¥ng {len(result.inserted_ids)} documents v√†o collection '{collection_name}'.")

                    except pymongo.errors.BulkWriteError as bwe:

                        success_count = bwe.details.get('nInserted', 0)

                        error_count = len(bwe.details.get('writeErrors', []))

                        logging.warning(f"L·ªói BulkWriteError khi ghi v√†o '{collection_name}'. "

                                        f"S·ªë l∆∞·ª£ng ghi th√†nh c√¥ng: {success_count}. "

                                        f"S·ªë l∆∞·ª£ng l·ªói: {error_count}.")

                        # Log chi ti·∫øt l·ªói ƒë·∫ßu ti√™n n·∫øu c√≥

                        if bwe.details.get('writeErrors'):

                            first_error = bwe.details['writeErrors'][0]

                            logging.warning(f"V√≠ d·ª• l·ªói ƒë·∫ßu ti√™n (index {first_error.get('index', 'N/A')}): Code {first_error.get('code', 'N/A')} - {first_error.get('errmsg', 'N/A')}")

                    except Exception as insert_err:

                        logging.error(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi ghi v√†o '{collection_name}': {insert_err}")

                        logging.error(traceback.format_exc()) # In traceback ƒë·ªÉ debug

                else:

                    # Ch·ªâ log info n·∫øu kh√¥ng c√≥ document n√†o ƒë∆∞·ª£c t·∫°o ra (v√† kh√¥ng c√≥ l·ªói tr∆∞·ªõc ƒë√≥)

                    if skipped_rows == df.shape[0]: # N·∫øu t·∫•t c·∫£ c√°c d√≤ng ƒë·ªÅu b·ªã b·ªè qua

                         logging.info(f"T·∫•t c·∫£ {df.shape[0]} d√≤ng d·ªØ li·ªáu trong file {os.path.basename(actual_file_path)} kh√¥ng h·ª£p l·ªá (thi·∫øu c·ªôt b·∫Øt bu·ªôc).")

                    else:

                        logging.info(f"Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá n√†o ƒë∆∞·ª£c t√¨m th·∫•y trong file {os.path.basename(actual_file_path)} ƒë·ªÉ ghi v√†o collection '{collection_name}'.")



            # B·∫Øt l·ªói chung khi ƒë·ªçc/x·ª≠ l√Ω file

            except Exception as read_err:

                logging.error(f"L·ªói nghi√™m tr·ªçng khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω file {os.path.basename(actual_file_path)}: {read_err}")

                logging.error(traceback.format_exc()) # In traceback ƒë·ªÉ debug



            logging.info(f"--- K·∫øt th√∫c x·ª≠ l√Ω file: {os.path.basename(actual_file_path)} ---")

        # K·∫øt th√∫c v√≤ng l·∫∑p for config_key, config...



        logging.info(f"Ho√†n t·∫•t qu√° tr√¨nh nh·∫≠p d·ªØ li·ªáu cho client (username): {username}")



    except pymongo.errors.ConfigurationError as ce:

        logging.error(f"L·ªói c·∫•u h√¨nh MongoDB URI: {ce}")

    except pymongo.errors.ConnectionFailure as cf:

        logging.error(f"L·ªói k·∫øt n·ªëi MongoDB: {cf}")

    except Exception as e:

        logging.error(f"ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën trong qu√° tr√¨nh x·ª≠ l√Ω ch√≠nh: {e}")

        logging.error(traceback.format_exc()) # In traceback ƒë·ªÉ debug

    finally:

        if mongo_client:

            mongo_client.close()

            logging.info("ƒê√£ ƒë√≥ng k·∫øt n·ªëi MongoDB.")



# --- Ch·∫°y th·ª≠ nghi·ªám (Gi·ªØ nguy√™n) ---

if __name__ == "__main__":

    test_client_id = "0302147168" # ID V√ç D·ª§ - C·∫¶N THAY TH·∫æ!

    get_data(test_client_id)

