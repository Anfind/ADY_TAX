# -*- coding: utf-8 -*-
"""ADY_Proj_Pandas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YJgg8S_I3gNL-3toz7DegJQ45U-cr38U
"""

# Commented out IPython magic to ensure Python compatibility.
# @title
# %pip install pandas numpy matplotlib seaborn plotly pymongo python-dotenv

# üì¶ Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
from datetime import datetime, timedelta
import pymongo
from pymongo import MongoClient
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# C·∫•u h√¨nh hi·ªÉn th·ªã
warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8')
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)

print("‚úÖ ƒê√£ import th√†nh c√¥ng t·∫•t c·∫£ th∆∞ vi·ªán c·∫ßn thi·∫øt!")
# üîó K·∫øt n·ªëi MongoDB Atlas
def connect_to_mongodb():
    """K·∫øt n·ªëi ƒë·∫øn MongoDB Atlas"""
    try:
        # L·∫•y th√¥ng tin t·ª´ .env
        mongo_uri = os.getenv('MONGO_URI', 'mongodb+srv://thaian:thaian123@taxanalyses.qxevmke.mongodb.net/?retryWrites=true&w=majority&appName=TaxAnalyses')
        db_name = os.getenv('MONGO_DB_NAME', 'MolaDatabase')

        # K·∫øt n·ªëi v·ªõi timeout
        client = MongoClient(mongo_uri, serverSelectionTimeoutMS=5000)
        db = client[db_name]

        # Test connection
        client.admin.command('ping')
        print(f"‚úÖ K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn MongoDB Atlas!")
        print(f"üìä Database: {db_name}")

        # Li·ªát k√™ collections v√† th·ªëng k√™
        collections = db.list_collection_names()
        print(f"üìÅ Collections c√≥ s·∫µn ({len(collections)}):")

        for coll_name in collections:
            count = db[coll_name].count_documents({})
            size = db.command("collStats", coll_name).get('size', 0)
            print(f"   ‚Ä¢ {coll_name}: {count:,} documents ({size/1024/1024:.2f} MB)")

        return client, db

    except Exception as e:
        print(f"‚ùå L·ªói k·∫øt n·ªëi: {e}")
        print("üí° Ki·ªÉm tra:")
        print("   - File .env c√≥ ƒë√∫ng MONGO_URI kh√¥ng?")
        print("   - K·∫øt n·ªëi internet ·ªïn ƒë·ªãnh kh√¥ng?")
        print("   - MongoDB Atlas c√≥ cho ph√©p IP hi·ªán t·∫°i kh√¥ng?")
        return None, None

# Th·ª±c hi·ªán k·∫øt n·ªëi
client, db = connect_to_mongodb()
# üìã Ph√¢n t√≠ch c·∫•u tr√∫c database
def analyze_database_structure(db):
    """Ph√¢n t√≠ch c·∫•u tr√∫c v√† th·ªëng k√™ c∆° b·∫£n c·ªßa database"""
    print("üîç PH√ÇN T√çCH C·∫§U TR√öC DATABASE")
    print("=" * 70)

    if db is None:
        print("‚ùå Kh√¥ng c√≥ k·∫øt n·ªëi database")
        return None

    structure_info = {}

    # Th·ª© t·ª± ∆∞u ti√™n collections (theo thi·∫øt k·∫ø h·ªá th·ªëng)
    collections_priority = ['invoices', 'invoice_items', 'invoice_analytics',
                           'HoaDonBanRa', 'HoaDonMuaVao']
    all_collections = db.list_collection_names()

    # S·∫Øp x·∫øp theo th·ª© t·ª± ∆∞u ti√™n
    sorted_collections = [c for c in collections_priority if c in all_collections]
    sorted_collections.extend([c for c in all_collections if c not in collections_priority])

    for collection_name in sorted_collections:
        collection = db[collection_name]

        # ƒê·∫øm documents
        count = collection.count_documents({})

        if count == 0:
            print(f"\nüìÅ Collection: {collection_name} - ‚ö†Ô∏è TR·ªêNG")
            continue

        # L·∫•y sample document ƒë·ªÉ xem c·∫•u tr√∫c
        sample = collection.find_one()

        # Th·ªëng k√™ collection
        coll_stats = db.command("collStats", collection_name)
        size_mb = coll_stats.get('size', 0) / 1024 / 1024

        # L·∫•y indexes
        indexes = collection.list_indexes()
        index_names = [idx['name'] for idx in indexes]

        structure_info[collection_name] = {
            'count': count,
            'size_mb': size_mb,
            'sample_fields': list(sample.keys()) if sample else [],
            'indexes': index_names,
            'sample_doc': sample
        }

        print(f"\nüìÅ Collection: {collection_name}")
        print(f"   üìä S·ªë documents: {count:,}")
        print(f"   üíæ K√≠ch th∆∞·ªõc: {size_mb:.2f} MB")
        print(f"   üîß C√°c fields: {', '.join(structure_info[collection_name]['sample_fields'][:15])}")
        print(f"   üîë Indexes: {', '.join(index_names)}")

        # Th·ªëng k√™ theo th·ªùi gian n·∫øu c√≥ tr∆∞·ªùng date
        date_fields = ['issue_date', 'created_at', 'date', 'Ng√†y l·∫≠p h√≥a ƒë∆°n']
        date_field = None

        for field in date_fields:
            if field in sample:
                date_field = field
                break

        if date_field:
            try:
                # T√¨m kho·∫£ng th·ªùi gian
                date_range = list(collection.aggregate([
                    {
                        "$match": {
                            date_field: {"$exists": True, "$ne": None}
                        }
                    },
                    {
                        "$group": {
                            "_id": None,
                            "min_date": {"$min": f"${date_field}"},
                            "max_date": {"$max": f"${date_field}"},
                            "count": {"$sum": 1}
                        }
                    }
                ]))

                if date_range and date_range[0]['count'] > 0:
                    min_date = date_range[0]['min_date']
                    max_date = date_range[0]['max_date']
                    print(f"   üìÖ Kho·∫£ng th·ªùi gian: {min_date} ‚Üí {max_date}")

                    # T√≠nh s·ªë ng√†y
                    if isinstance(min_date, str) and isinstance(max_date, str):
                        try:
                            min_dt = pd.to_datetime(min_date)
                            max_dt = pd.to_datetime(max_date)
                            days_diff = (max_dt - min_dt).days
                            print(f"   ‚è±Ô∏è  Th·ªùi gian: {days_diff} ng√†y")
                        except:
                            pass
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Kh√¥ng th·ªÉ ph√¢n t√≠ch th·ªùi gian: {e}")

        # Hi·ªÉn th·ªã sample document structure (nested)
        print(f"   üìã C·∫•u tr√∫c d·ªØ li·ªáu m·∫´u:")
        for key, value in list(sample.items())[:10]:
            value_type = type(value).__name__
            if isinstance(value, dict):
                print(f"      ‚Ä¢ {key}: {{object}} - {list(value.keys())[:5]}")
            elif isinstance(value, list):
                print(f"      ‚Ä¢ {key}: [array] - length: {len(value)}")
            else:
                print(f"      ‚Ä¢ {key}: {value_type}")

    return structure_info

# Ph√¢n t√≠ch c·∫•u tr√∫c
if db is not None:
    db_structure = analyze_database_structure(db)
else:
    print("‚ùå Kh√¥ng th·ªÉ ph√¢n t√≠ch do l·ªói k·∫øt n·ªëi")
# üîÑ ƒê·ªçc d·ªØ li·ªáu t·ª´ c√°c collections (PHI√äN B·∫¢N T·ªêI ∆ØU)
def load_data_to_dataframes(db, limit=5000):
    """ƒê·ªçc d·ªØ li·ªáu t·ª´ MongoDB v√† chuy·ªÉn th√†nh DataFrame"""
    dataframes = {}

    if db is None:
        print("‚ùå Database connection not available")
        return dataframes

    # Collection theo thi·∫øt k·∫ø h·ªá th·ªëng (∆∞u ti√™n collections m·ªõi)
    collections_info = {
        'invoices': {
            'description': 'H√≥a ƒë∆°n ch√≠nh (c·∫•u tr√∫c m·ªõi)',
            'priority': 1,
            'nested_fields': ['seller', 'buyer', 'financial_summary', 'processing_info']
        },
        'invoice_items': {
            'description': 'Chi ti·∫øt s·∫£n ph·∫©m/d·ªãch v·ª•',
            'priority': 2,
            'nested_fields': []
        },
        'invoice_analytics': {
            'description': 'Ph√¢n t√≠ch t·ªïng h·ª£p (auto-generated)',
            'priority': 3,
            'nested_fields': []
        },
        'HoaDonBanRa': {
            'description': 'H√≥a ƒë∆°n b√°n ra (legacy/raw)',
            'priority': 4,
            'nested_fields': []
        },
        'HoaDonMuaVao': {
            'description': 'H√≥a ƒë∆°n mua v√†o (legacy/raw)',
            'priority': 5,
            'nested_fields': []
        }
    }

    # S·∫Øp x·∫øp theo priority
    sorted_collections = sorted(collections_info.items(), key=lambda x: x[1]['priority'])

    for collection_name, info in sorted_collections:
        try:
            if collection_name not in db.list_collection_names():
                print(f"‚ö†Ô∏è  Collection '{collection_name}' kh√¥ng t·ªìn t·∫°i")
                continue

            total_count = db[collection_name].count_documents({})

            if total_count == 0:
                print(f"\nüìñ {info['description']} [{collection_name}] - TR·ªêNG")
                continue

            print(f"\nüìñ ƒêang ƒë·ªçc: {info['description']} [{collection_name}]")
            print(f"   üìä T·ªïng: {total_count:,} documents")

            # Query v·ªõi limit n·∫øu c·∫ßn
            if limit and total_count > limit:
                print(f"   ‚ö° Gi·ªõi h·∫°n: {limit:,} documents (ƒë·ªÉ tƒÉng t·ªëc)")
                cursor = db[collection_name].find({}).limit(limit)
            else:
                cursor = db[collection_name].find({})

            # Chuy·ªÉn ƒë·ªïi sang DataFrame
            print(f"   ‚è≥ ƒêang t·∫£i d·ªØ li·ªáu...")
            data = list(cursor)

            if not data:
                print(f"   ‚ö†Ô∏è  Kh√¥ng c√≥ d·ªØ li·ªáu")
                continue

            df = pd.DataFrame(data)

            # X·ª≠ l√Ω ObjectId
            if '_id' in df.columns:
                df['_id'] = df['_id'].astype(str)

            # X·ª≠ l√Ω nested fields (flatten) - CH·ªà v·ªõi invoices
            if collection_name == 'invoices':
                for nested_field in info['nested_fields']:
                    if nested_field in df.columns and df[nested_field].notna().any():
                        first_val = df[nested_field].dropna().iloc[0] if len(df[nested_field].dropna()) > 0 else None

                        if isinstance(first_val, dict):
                            try:
                                # Flatten nested dictionary
                                nested_df = pd.json_normalize(df[nested_field])
                                nested_df.columns = [f"{nested_field}.{col}" for col in nested_df.columns]
                                df = pd.concat([df, nested_df], axis=1)
                                print(f"   üîÑ ƒê√£ flatten: {nested_field}")
                            except:
                                pass

            # Chuy·ªÉn ƒë·ªïi date fields sang datetime (NHANH H∆†N)
            date_fields = ['issue_date', 'created_at', 'updated_at', 'date', 'Ng√†y l·∫≠p h√≥a ƒë∆°n']

            for field in date_fields:
                if field in df.columns:
                    try:
                        df[field] = pd.to_datetime(df[field], errors='coerce')
                    except:
                        pass

            # Chuy·ªÉn ƒë·ªïi numeric fields (NHANH H∆†N)
            numeric_fields = ['T·ªïng ti·ªÅn thanh to√°n', 'Ti·ªÅn thu·∫ø', 'Th√†nh ti·ªÅn ch∆∞a thu·∫ø',
                            'S·ªë l∆∞·ª£ng', 'ƒê∆°n gi√°', 'total_amount', 'tax_amount', 'subtotal']

            for field in numeric_fields:
                if field in df.columns:
                    try:
                        df[field] = pd.to_numeric(df[field], errors='coerce')
                    except:
                        pass

            dataframes[collection_name] = df

            # Th·ªëng k√™ nhanh
            print(f"   ‚úÖ ƒê√£ t·∫£i: {len(df):,} rows √ó {len(df.columns)} columns")
            print(f"   üíæ Memory: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")

        except Exception as e:
            print(f"   ‚ùå L·ªói: {e}")

    # T√≥m t·∫Øt
    print(f"\n{'='*70}")
    print(f"üìä T·ªîNG K·∫æT: {len(dataframes)} collections, {sum(len(df) for df in dataframes.values()):,} records")
    print(f"{'='*70}")

    return dataframes

# ‚ö° ƒê·ªåC D·ªÆ LI·ªÜU V·ªöI GI·ªöI H·∫†N (Nhanh h∆°n)
print("üöÄ B·∫Øt ƒë·∫ßu ƒë·ªçc d·ªØ li·ªáu t·ª´ MongoDB Atlas...")
print("‚ö° S·ª≠ d·ª•ng limit ƒë·ªÉ tƒÉng t·ªëc ph√¢n t√≠ch\n")

# THAY ƒê·ªîI ·ªû ƒê√ÇY: Gi·ªõi h·∫°n 5000 records/collection ƒë·ªÉ ch·∫°y nhanh
# N·∫øu mu·ªën ƒë·ªçc TO√ÄN B·ªò: d√πng limit=None (s·∫Ω ch·∫°y l√¢u h∆°n)
dfs = load_data_to_dataframes(db, limit=5000)  # ‚ö° Gi·ªõi h·∫°n 5000 records

# üìà Ph√¢n t√≠ch c∆° b·∫£n t·ª´ng DataFrame
def basic_analysis(dfs):
    """Ph√¢n t√≠ch c∆° b·∫£n cho t·ª´ng DataFrame"""

    for name, df in dfs.items():
        print(f"\nüìä PH√ÇN T√çCH C∆† B·∫¢N: {name.upper()}")
        print("=" * 60)

        # Th√¥ng tin c∆° b·∫£n
        print(f"üî¢ K√≠ch th∆∞·ªõc: {df.shape[0]:,} rows x {df.shape[1]} columns")
        print(f"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

        # Ki·ªÉm tra missing values
        missing = df.isnull().sum()
        if missing.sum() > 0:
            print(f"\n‚ö†Ô∏è Missing values:")
            missing_pct = (missing / len(df) * 100).round(2)
            for col in missing[missing > 0].index:
                print(f"   {col}: {missing[col]:,} ({missing_pct[col]}%)")
        else:
            print("‚úÖ Kh√¥ng c√≥ missing values")

        # Data types
        print(f"\nüè∑Ô∏è Data types:")
        type_counts = df.dtypes.value_counts()
        for dtype, count in type_counts.items():
            print(f"   {dtype}: {count} columns")

        # Hi·ªÉn th·ªã sample data
        print(f"\nüìã Sample data (5 rows ƒë·∫ßu):")
        display(df.head())

        # N·∫øu c√≥ c·ªôt s·ªë, hi·ªÉn th·ªã th·ªëng k√™ m√¥ t·∫£
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            print(f"\nüìä Th·ªëng k√™ m√¥ t·∫£ (numeric columns):")
            display(df[numeric_cols].describe())

# Th·ª±c hi·ªán ph√¢n t√≠ch c∆° b·∫£n
if dfs:
    basic_analysis(dfs)
else:
    print("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch")

#Trung b√¨nh doanh thu h√≥a ƒë∆°n theo th√°ng
avg_months = dfs['invoice_analytics'].groupby('month')['total_revenue'].mean().reset_index()
display(avg_months)

# V·∫Ω bi·ªÉu ƒë·ªì c·ªôt
plt.figure(figsize=(15, 7))
sns.barplot(data=avg_months, x='month', y='total_revenue', color='skyblue')
plt.title('Doanh thu trung b√¨nh h√≥a ƒë∆°n theo th√°ng')
plt.xlabel('Th√°ng')
plt.ylabel('Doanh thu trung b√¨nh')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

#Top s·∫£n ph·∫©m/d·ªãch v·ª• b√°n ch·∫°y nh·∫•t
top_items = dfs['invoice_items'].groupby('item_name')
display(top_items[['item_name', 'quantity']].sum('quantity').sort_values(by='quantity', ascending = False))

#Doanh thu v√† thu·∫ø theo ng∆∞·ªùi mua
top_revenue_tax_buyer = dfs['invoice_analytics'].groupby('buyer_name')[['total_revenue', 'total_tax']].sum().sort_values(by='total_revenue', ascending=False)
display(top_revenue_tax_buyer)

# V·∫Ω bi·ªÉu ƒë·ªì c·ªôt cho top 10 ng∆∞·ªùi mua
plt.figure(figsize=(15, 8))
top_revenue_tax_buyer.head(10).plot(kind='bar', y=['total_revenue', 'total_tax'], ax=plt.gca())
plt.title('T·ªïng doanh thu v√† thu·∫ø theo ng∆∞·ªùi mua (Top 10)')
plt.xlabel('T√™n ng∆∞·ªùi mua')
plt.ylabel('T·ªïng gi√° tr·ªã')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Doanh thu trung b√¨nh theo tr·∫°ng th√°i h√≥a ƒë∆°n
avg_status = dfs['invoice_analytics'].groupby('invoice_status')['total_revenue'].mean().reset_index()
display(avg_status)

# V·∫Ω bi·ªÉu ƒë·ªì c·ªôt
plt.figure(figsize=(10, 6))
sns.barplot(data=avg_status, x='invoice_status', y='total_revenue', palette='viridis')
plt.title('Doanh thu trung b√¨nh theo tr·∫°ng th√°i h√≥a ƒë∆°n')
plt.xlabel('Tr·∫°ng th√°i h√≥a ƒë∆°n')
plt.ylabel('Doanh thu trung b√¨nh')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

#Doanh thu theo th√°ng v√† h√¨nh th·ª©c thanh to√°n
top_revenue_month = dfs['invoice_analytics'].groupby(['month', 'payment_method'])['total_revenue'].sum().reset_index()
display(top_revenue_month)

# V·∫Ω bi·ªÉu ƒë·ªì c·ªôt
plt.figure(figsize=(15, 7))
sns.barplot(data=top_revenue_month, x='month', y='total_revenue', hue='payment_method')
plt.title('Doanh thu theo th√°ng v√† h√¨nh th·ª©c thanh to√°n')
plt.xlabel('Th√°ng')
plt.ylabel('T·ªïng doanh thu')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()